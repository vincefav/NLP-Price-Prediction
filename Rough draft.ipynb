{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "data=None\n",
    "def absolute_correlations(col, df=data):\n",
    "    corrs = pd.DataFrame(df.select_dtypes(include=[np.number]).corrwith(df[col]), columns=['correlation'])\n",
    "    corrs['absol'] = np.abs(corrs['correlation'])\n",
    "    return corrs.sort_values('absol', ascending=False).drop('absol', axis=1).tail(len(corrs)-1)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "data = data.sample(frac=1.0)\n",
    "combi = data.sample(20000)\n",
    "\n",
    "combi['item_description'] = combi['item_description'].fillna('_BLANK_')\n",
    "\n",
    "data = combi.head(10000) #training set\n",
    "test = combi.tail(10000)\n",
    "\n",
    "y = np.log1p(data.pop('price'))\n",
    "ytest = np.log1p(test.pop('price'))\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split (sub)categories into separate columns \n",
    "cats = data['category_name'].str.split('/', expand=True) #can also add n=3\n",
    "cats.columns = ['category_' + str(i) for i in cats.columns]\n",
    "del data['category_name']\n",
    "\n",
    "# Add to original dataframe\n",
    "data = pd.concat([data, cats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283 brands meet this criteria. Brands most strongly correlated with price include:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Louis Vuitton</th>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Kors</th>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Air Jordan</th>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendra Scott</th>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lululemon</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               correlation\n",
       "Louis Vuitton        0.120\n",
       "Michael Kors         0.113\n",
       "Air Jordan           0.106\n",
       "Kendra Scott         0.093\n",
       "Lululemon            0.088"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands = pd.get_dummies(data['brand_name'])\n",
    "brands['y'] = y\n",
    "\n",
    "top_brands = absolute_correlations('y', df=brands)\n",
    "\n",
    "# Save the brands that are correlated with price\n",
    "top_brands_by_corr = top_brands[abs(top_brands.correlation) > .01].index\n",
    "\n",
    "print(len(top_brands_by_corr), 'brands meet this criteria. Brands most strongly correlated with price include:')\n",
    "\n",
    "top_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 brands meet this criteria. Most common brands include:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nike                 371\n",
       "PINK                 356\n",
       "Victoria's Secret    313\n",
       "LuLaRoe              201\n",
       "FOREVER 21           119\n",
       "Name: brand_name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_brands = data['brand_name'].value_counts()\n",
    "\n",
    "# Take only those that appear in more than 1/1000 listings\n",
    "common_brands = common_brands[common_brands > (len(data) * 1/1000)]\n",
    "\n",
    "#Save their names\n",
    "top_brands_by_commonality = common_brands.index\n",
    "\n",
    "print(len(common_brands), 'brands meet this criteria. Most common brands include:')\n",
    "\n",
    "common_brands[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine brands meeting either criterion\n",
    "top_brands_all = set(top_brands_by_commonality).union(set(top_brands_by_corr))\n",
    "\n",
    "len(top_brands_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brands_old = data.pop('brand_name')\n",
    "\n",
    "data['brand_name'] = 'Other'\n",
    "\n",
    "for i in top_brands:\n",
    "    data['brand_name'] = np.where(brands_old.isin(top_brands_all),brands_old, data['brand_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245237       Style&co.\n",
       "637129            Other\n",
       "193904            Other\n",
       "824211            Other\n",
       "492128              MAC\n",
       "195074            Other\n",
       "643940            Other\n",
       "849893            Other\n",
       "624957     Michael Kors\n",
       "642388            Coach\n",
       "Name: brand_name, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lots of less-noteworthy brands are now labeled \"Other\"\n",
    "data['brand_name'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(min_df=10, max_df=.2).fit(combi['item_description'])\n",
    "\n",
    "item_grid = pd.DataFrame(tf.transform(data['item_description']).todense())\n",
    "item_grid.columns = ['contains_' + i for i in tf.get_feature_names()]\n",
    "\n",
    "item_grid['train_id'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3701)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat item grid to original dataframe\n",
    "data = pd.merge(data, item_grid, on=['train_id'])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4634)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummify categories and brand names\n",
    "\n",
    "cat0_dums = pd.get_dummies(data['category_0'], prefix='cat0')\n",
    "cat1_dums = pd.get_dummies(data['category_1'], prefix='cat1')\n",
    "cat2_dums = pd.get_dummies(data['category_2'], prefix='cat2')\n",
    "cat3_dums = pd.get_dummies(data['category_3'], prefix='cat3')\n",
    "cat4_dums = pd.get_dummies(data['category_4'], prefix='cat4')\n",
    "\n",
    "data = pd.concat([data, cat0_dums], axis=1)\n",
    "data = pd.concat([data, cat1_dums], axis=1)\n",
    "data = pd.concat([data, cat2_dums], axis=1)\n",
    "data = pd.concat([data, cat3_dums], axis=1)\n",
    "data = pd.concat([data, cat4_dums], axis=1)\n",
    "\n",
    "name_dums = pd.get_dummies(data['brand_name'], prefix='brandname')\n",
    "data = pd.concat([data, name_dums], axis=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=1000, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('xgboost', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max...,\n",
      "       reg_alpha=0, reg_lambda=1.0, scale_pos_weight=1, seed=0,\n",
      "       silent=True, subsample=1))])\n",
      "Mean score: 0.336957056036\n",
      "Std Dev:    0.00891280115213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('xgboost', XGBRegressor())\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'pca__n_components': [1000],\n",
    "    'xgboost__n_estimators': [200],\n",
    "    'xgboost__max_depth': [4],\n",
    "    'xgboost__reg_lambda': [1.0,1.5]\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "print(model)\n",
    "cv = cross_val_score(model, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=1000, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('xgboost', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max...,\n",
       "       reg_alpha=0, reg_lambda=1.0, scale_pos_weight=1, seed=0,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test.select_dtypes(include=[np.number]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

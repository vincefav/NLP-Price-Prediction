{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from warnings import filterwarnings\n",
    "#filterwarnings('ignore')\n",
    "\n",
    "data=None\n",
    "def absolute_correlations(col, df=data):\n",
    "    corrs = pd.DataFrame(df.select_dtypes(include=[np.number]).corrwith(df[col]), columns=['correlation'])\n",
    "    corrs['absol'] = np.abs(corrs['correlation'])\n",
    "    return corrs.sort_values('absol', ascending=False).drop('absol', axis=1).tail(len(corrs)-1)\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.tsv', sep='\\t')\n",
    "\n",
    "data = data.sample(frac=1.0)\n",
    "data = data.sample(10000)\n",
    "\n",
    "y = np.log1p(data.pop('price'))\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split (sub)categories into separate columns \n",
    "cats = data['category_name'].str.split('/', expand=True) #can also add n=3\n",
    "cats.columns = ['category_' + str(i) for i in cats.columns]\n",
    "del data['category_name']\n",
    "\n",
    "# Add to original dataframe\n",
    "data = pd.concat([data, cats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 brands meet this criteria. Brands most strongly correlated with price include:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Louis Vuitton</th>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Kors</th>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lululemon</th>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kendra Scott</th>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               correlation\n",
       "Louis Vuitton        0.121\n",
       "Michael Kors         0.114\n",
       "Lululemon            0.104\n",
       "Kendra Scott         0.092\n",
       "Apple                0.088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brands = pd.get_dummies(data['brand_name'])\n",
    "brands['y'] = y\n",
    "\n",
    "top_brands = absolute_correlations('y', df=brands)\n",
    "\n",
    "# Save the brands that are correlated with price\n",
    "top_brands_by_corr = top_brands[abs(top_brands.correlation) > .01].index\n",
    "\n",
    "print(len(top_brands_by_corr), 'brands meet this criteria. Brands most strongly correlated with price include:')\n",
    "\n",
    "top_brands.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 brands meet this criteria. Most common brands include:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nike                 390\n",
       "PINK                 341\n",
       "Victoria's Secret    300\n",
       "LuLaRoe              217\n",
       "Apple                124\n",
       "Name: brand_name, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_brands = data['brand_name'].value_counts()\n",
    "\n",
    "# Take only those that appear in more than 1/1000 listings\n",
    "common_brands = common_brands[common_brands > (len(data) * 1/1000)]\n",
    "\n",
    "#Save their names\n",
    "top_brands_by_commonality = common_brands.index\n",
    "\n",
    "print(len(common_brands), 'brands meet this criteria. Most common brands include:')\n",
    "\n",
    "common_brands[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine brands meeting either criterion\n",
    "top_brands_all = set(top_brands_by_commonality).union(set(top_brands_by_corr))\n",
    "\n",
    "len(top_brands_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brands_old = data.pop('brand_name')\n",
    "\n",
    "data['brand_name'] = 'Other'\n",
    "\n",
    "for i in top_brands:\n",
    "    data['brand_name'] = np.where(brands_old.isin(top_brands_all),brands_old, data['brand_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390492              Other\n",
       "1168773             Other\n",
       "292061              Other\n",
       "907625              Other\n",
       "1332725             Other\n",
       "1050822          Columbia\n",
       "63172      American Eagle\n",
       "454615         Kate Spade\n",
       "1442357             Other\n",
       "461411              Other\n",
       "Name: brand_name, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lots of less-noteworthy brands are now labeled \"Other\"\n",
    "data['brand_name'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data['item_description'] = data['item_description'].fillna('_BLANK_')\n",
    "tf = TfidfVectorizer(min_df=10, max_df=.2).fit(data['item_description'])\n",
    "\n",
    "item_grid = pd.DataFrame(tf.transform(data['item_description']).todense())\n",
    "item_grid.columns = ['contains_' + i for i in tf.get_feature_names()]\n",
    "\n",
    "item_grid['train_id'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2374)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat item grid to original dataframe\n",
    "data = pd.merge(data, item_grid, on=['train_id'])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3305)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummify categories and brand names\n",
    "\n",
    "cat0_dums = pd.get_dummies(data['category_0'], prefix='cat0')\n",
    "cat1_dums = pd.get_dummies(data['category_1'], prefix='cat1')\n",
    "cat2_dums = pd.get_dummies(data['category_2'], prefix='cat2')\n",
    "cat3_dums = pd.get_dummies(data['category_3'], prefix='cat3')\n",
    "cat4_dums = pd.get_dummies(data['category_4'], prefix='cat4')\n",
    "\n",
    "data = pd.concat([data, cat0_dums], axis=1)\n",
    "data = pd.concat([data, cat1_dums], axis=1)\n",
    "data = pd.concat([data, cat2_dums], axis=1)\n",
    "data = pd.concat([data, cat3_dums], axis=1)\n",
    "data = pd.concat([data, cat4_dums], axis=1)\n",
    "\n",
    "name_dums = pd.get_dummies(data['brand_name'], prefix='brandname')\n",
    "data = pd.concat([data, name_dums], axis=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.300726012807\n",
      "Std Dev:    0.00642314300548\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(XGBRegressor(), data.select_dtypes(include=[np.number]), y, cv=4, scoring='r2')\n",
    "# .266560686779\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max...=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Mean score: 0.289374246774\n",
      "Std Dev:    0.00728806061989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "pl = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('classify', XGBRegressor())\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'pca__n_components': [1000,100],\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model_binary = grid.best_estimator_\n",
    "print(model_binary)\n",
    "cv = cross_val_score(model_binary, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=1000, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       ma...=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Mean score: 0.303638788257\n",
      "Std Dev:    0.0115789803086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "pl = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('classify', XGBRegressor())\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'pca__n_components': [1000,3297],\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model_binary = grid.best_estimator_\n",
    "print(model_binary)\n",
    "cv = cross_val_score(model_binary, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = PCA(n_components=1000).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xg = XGBRegressor()\n",
    "\n",
    "params = [{\n",
    "    'n_estimators': [50, 200],\n",
    "    'max_depth': [2,3,4,5]\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(xg, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "print(model)\n",
    "cv = cross_val_score(model, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=5, max_df=.05).fit(data['name'])\n",
    "\n",
    "name_grid = pd.DataFrame(tf.transform(data['name']).todense())\n",
    "name_grid.columns = ['name_' + i for i in tf.get_feature_names()]\n",
    "\n",
    "name_grid['train_id'] = data['train_id']\n",
    "\n",
    "# data = pd.merge(data, name_grid, on=['train_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "      <th>...</th>\n",
       "      <th>name_zip</th>\n",
       "      <th>name_zone</th>\n",
       "      <th>cat0_Beauty</th>\n",
       "      <th>cat0_Electronics</th>\n",
       "      <th>cat0_Home</th>\n",
       "      <th>cat0_Kids</th>\n",
       "      <th>cat0_Men</th>\n",
       "      <th>cat0_Other</th>\n",
       "      <th>cat0_Sports &amp; Outdoors</th>\n",
       "      <th>cat0_Women</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2177</td>\n",
       "      <td>Chanel T SHIRT (L)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Size Large Custom Made :)</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>T-Shirts</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4786</td>\n",
       "      <td>Black sandals</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Sam &amp; Libby brand sandals. Worn once for a wed...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>Sandals</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3089</td>\n",
       "      <td>Dr. Drew Beats Extra Cord Wire</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This came with my Dr. Dre Solos but I don't ne...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>TV, Audio &amp; Surveillance</td>\n",
       "      <td>Portable Audio &amp; Accessories</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3842</td>\n",
       "      <td>Oral B precision clean brush heads</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Both brand new still sealed</td>\n",
       "      <td>Other</td>\n",
       "      <td>Daily &amp; Travel items</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2905</td>\n",
       "      <td>Black Supreme New Era Headband</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>Men</td>\n",
       "      <td>Men's Accessories</td>\n",
       "      <td>Hats</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6508</td>\n",
       "      <td>Rae Dunn Shine Mug</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Rae Dunn Summer Collection, Shine Mug.</td>\n",
       "      <td>Home</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "      <td>Coffee &amp; Tea Accessories</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1810</td>\n",
       "      <td>NWOT Coach bag &amp; wallet, FINAL SALE[rm]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NWOT leather pebble two tone set. The colors a...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Women's Handbags</td>\n",
       "      <td>Shoulder Bag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1153</td>\n",
       "      <td>4-pairs New VS Pink boyshort panties XS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Please read, before buying :-). Don't ever rat...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>Panties</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2649</td>\n",
       "      <td>Rae Dunn Spoon and Dance Mug</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>***RESERVED FOR BARBARAARY**** 1 Brand New Rae...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "      <td>Kitchen Utensils &amp; Gadgets</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6742</td>\n",
       "      <td>Estée Lauder ampoules set</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>New Estee Lauder Advanced Night Repair Ampoule...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Face</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7368</td>\n",
       "      <td>kendra scott necklace</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>hot pink Dylan necklace, worn once no tags (ma...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2311</td>\n",
       "      <td>Bundle Michael Kors underwear large</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Brand new</td>\n",
       "      <td>Men</td>\n",
       "      <td>Athletic Apparel</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1303</td>\n",
       "      <td>Jouer highlighter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Jouer mini highlighter in ice BNIB AUTHENTIC</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>Makeup</td>\n",
       "      <td>Face</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1324</td>\n",
       "      <td>Steph Curry Jersey</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>brand new</td>\n",
       "      <td>Sports &amp; Outdoors</td>\n",
       "      <td>Fan Shop</td>\n",
       "      <td>NBA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4910</td>\n",
       "      <td>Lps</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Some lps may have some minor scuffs or doodles...</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Dolls &amp; Accessories</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7007</td>\n",
       "      <td>Toy Monster Truck Lot</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Includes silver grave digger 2005-2007 release...</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Action Figures &amp; Statues</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4298</td>\n",
       "      <td>Trail rated badge for Jeep</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Black/silver</td>\n",
       "      <td>Other</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Exterior Accessories</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2415</td>\n",
       "      <td>Rose Water</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>New... Big Bottle</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>Skin Care</td>\n",
       "      <td>Face</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3211</td>\n",
       "      <td>Vanilla creampuff slime</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-fluffy and thick -stretchy and fun to poke -s...</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Toys</td>\n",
       "      <td>Arts &amp; Crafts</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1890</td>\n",
       "      <td>NWT Lularoe Leggings OS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Seagulls</td>\n",
       "      <td>Women</td>\n",
       "      <td>Athletic Apparel</td>\n",
       "      <td>Pants, Tights, Leggings</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2098</td>\n",
       "      <td>NWT ANTLER NECKLACE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Deer Antler Necklace CA Lead and Nickel Compli...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5820</td>\n",
       "      <td>1/2 POUND MINT SLIME</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1/2 pounds of mint scented slime no free shipp...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4652</td>\n",
       "      <td>NWT PSP memory stick w/ adapter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>New in package 8gb</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Tablets</td>\n",
       "      <td>Drives, Storage &amp; Media</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7142</td>\n",
       "      <td>Infant sneakers</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>Kids</td>\n",
       "      <td>Boys 0-24 Mos</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5448</td>\n",
       "      <td>LOUIS VUITTON PINK DAMIER NEVERFULL</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Like new louis vuitton neverfull bag!i believe...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Women's Handbags</td>\n",
       "      <td>Shoulder Bag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                     name  item_condition_id  \\\n",
       "0      2177                       Chanel T SHIRT (L)                  1   \n",
       "1      4786                            Black sandals                  3   \n",
       "2      3089           Dr. Drew Beats Extra Cord Wire                  1   \n",
       "3      3842       Oral B precision clean brush heads                  1   \n",
       "4      2905           Black Supreme New Era Headband                  2   \n",
       "5      6508                       Rae Dunn Shine Mug                  1   \n",
       "6      1810  NWOT Coach bag & wallet, FINAL SALE[rm]                  2   \n",
       "7      1153  4-pairs New VS Pink boyshort panties XS                  1   \n",
       "8      2649             Rae Dunn Spoon and Dance Mug                  2   \n",
       "9      6742                Estée Lauder ampoules set                  1   \n",
       "10     7368                    kendra scott necklace                  2   \n",
       "11     2311      Bundle Michael Kors underwear large                  1   \n",
       "12     1303                        Jouer highlighter                  1   \n",
       "13     1324                       Steph Curry Jersey                  1   \n",
       "14     4910                                      Lps                  3   \n",
       "15     7007                    Toy Monster Truck Lot                  2   \n",
       "16     4298               Trail rated badge for Jeep                  1   \n",
       "17     2415                               Rose Water                  1   \n",
       "18     3211                  Vanilla creampuff slime                  1   \n",
       "19     1890                  NWT Lularoe Leggings OS                  1   \n",
       "20     2098                      NWT ANTLER NECKLACE                  1   \n",
       "21     5820                     1/2 POUND MINT SLIME                  1   \n",
       "22     4652          NWT PSP memory stick w/ adapter                  1   \n",
       "23     7142                          Infant sneakers                  3   \n",
       "24     5448      LOUIS VUITTON PINK DAMIER NEVERFULL                  2   \n",
       "\n",
       "    shipping                                   item_description  \\\n",
       "0          1                          Size Large Custom Made :)   \n",
       "1          0  Sam & Libby brand sandals. Worn once for a wed...   \n",
       "2          1  This came with my Dr. Dre Solos but I don't ne...   \n",
       "3          1                        Both brand new still sealed   \n",
       "4          0                                 No description yet   \n",
       "5          0             Rae Dunn Summer Collection, Shine Mug.   \n",
       "6          0  NWOT leather pebble two tone set. The colors a...   \n",
       "7          0  Please read, before buying :-). Don't ever rat...   \n",
       "8          0  ***RESERVED FOR BARBARAARY**** 1 Brand New Rae...   \n",
       "9          1  New Estee Lauder Advanced Night Repair Ampoule...   \n",
       "10         1  hot pink Dylan necklace, worn once no tags (ma...   \n",
       "11         0                                          Brand new   \n",
       "12         0       Jouer mini highlighter in ice BNIB AUTHENTIC   \n",
       "13         0                                          brand new   \n",
       "14         0  Some lps may have some minor scuffs or doodles...   \n",
       "15         0  Includes silver grave digger 2005-2007 release...   \n",
       "16         1                                       Black/silver   \n",
       "17         0                                  New... Big Bottle   \n",
       "18         1  -fluffy and thick -stretchy and fun to poke -s...   \n",
       "19         1                                           Seagulls   \n",
       "20         0  Deer Antler Necklace CA Lead and Nickel Compli...   \n",
       "21         0  1/2 pounds of mint scented slime no free shipp...   \n",
       "22         1                                 New in package 8gb   \n",
       "23         0                                 No description yet   \n",
       "24         1  Like new louis vuitton neverfull bag!i believe...   \n",
       "\n",
       "           category_0                category_1                    category_2  \\\n",
       "0               Women            Tops & Blouses                      T-Shirts   \n",
       "1               Women                     Shoes                       Sandals   \n",
       "2         Electronics  TV, Audio & Surveillance  Portable Audio & Accessories   \n",
       "3               Other      Daily & Travel items                 Personal Care   \n",
       "4                 Men         Men's Accessories                          Hats   \n",
       "5                Home          Kitchen & Dining      Coffee & Tea Accessories   \n",
       "6               Women          Women's Handbags                  Shoulder Bag   \n",
       "7               Women                 Underwear                       Panties   \n",
       "8                Home          Kitchen & Dining    Kitchen Utensils & Gadgets   \n",
       "9              Beauty                    Makeup                          Face   \n",
       "10              Women                   Jewelry                     Necklaces   \n",
       "11                Men          Athletic Apparel                        Shorts   \n",
       "12             Beauty                    Makeup                          Face   \n",
       "13  Sports & Outdoors                  Fan Shop                           NBA   \n",
       "14               Kids                      Toys           Dolls & Accessories   \n",
       "15               Kids                      Toys      Action Figures & Statues   \n",
       "16              Other                Automotive          Exterior Accessories   \n",
       "17             Beauty                 Skin Care                          Face   \n",
       "18               Kids                      Toys                 Arts & Crafts   \n",
       "19              Women          Athletic Apparel       Pants, Tights, Leggings   \n",
       "20              Women                   Jewelry                     Necklaces   \n",
       "21              Other                     Other                         Other   \n",
       "22        Electronics       Computers & Tablets       Drives, Storage & Media   \n",
       "23               Kids             Boys 0-24 Mos                         Shoes   \n",
       "24              Women          Women's Handbags                  Shoulder Bag   \n",
       "\n",
       "   category_3 category_4     ...     name_zip  name_zone  cat0_Beauty  \\\n",
       "0        None       None     ...        0.000      0.000            0   \n",
       "1        None       None     ...        0.000      0.000            0   \n",
       "2        None       None     ...        0.000      0.000            0   \n",
       "3        None       None     ...        0.000      0.000            0   \n",
       "4        None       None     ...        0.000      0.000            0   \n",
       "5        None       None     ...        0.000      0.000            0   \n",
       "6        None       None     ...        0.000      0.000            0   \n",
       "7        None       None     ...        0.000      0.000            0   \n",
       "8        None       None     ...        0.000      0.000            0   \n",
       "9        None       None     ...        0.000      0.000            1   \n",
       "10       None       None     ...        0.000      0.000            0   \n",
       "11       None       None     ...        0.000      0.000            0   \n",
       "12       None       None     ...        0.000      0.000            1   \n",
       "13       None       None     ...        0.000      0.000            0   \n",
       "14       None       None     ...        0.000      0.000            0   \n",
       "15       None       None     ...        0.000      0.000            0   \n",
       "16       None       None     ...        0.000      0.000            0   \n",
       "17       None       None     ...        0.000      0.000            1   \n",
       "18       None       None     ...        0.000      0.000            0   \n",
       "19       None       None     ...        0.000      0.000            0   \n",
       "20       None       None     ...        0.000      0.000            0   \n",
       "21       None       None     ...        0.000      0.000            0   \n",
       "22       None       None     ...        0.000      0.000            0   \n",
       "23       None       None     ...        0.000      0.000            0   \n",
       "24       None       None     ...        0.000      0.000            0   \n",
       "\n",
       "    cat0_Electronics  cat0_Home  cat0_Kids  cat0_Men  cat0_Other  \\\n",
       "0                  0          0          0         0           0   \n",
       "1                  0          0          0         0           0   \n",
       "2                  1          0          0         0           0   \n",
       "3                  0          0          0         0           1   \n",
       "4                  0          0          0         1           0   \n",
       "5                  0          1          0         0           0   \n",
       "6                  0          0          0         0           0   \n",
       "7                  0          0          0         0           0   \n",
       "8                  0          1          0         0           0   \n",
       "9                  0          0          0         0           0   \n",
       "10                 0          0          0         0           0   \n",
       "11                 0          0          0         1           0   \n",
       "12                 0          0          0         0           0   \n",
       "13                 0          0          0         0           0   \n",
       "14                 0          0          1         0           0   \n",
       "15                 0          0          1         0           0   \n",
       "16                 0          0          0         0           1   \n",
       "17                 0          0          0         0           0   \n",
       "18                 0          0          1         0           0   \n",
       "19                 0          0          0         0           0   \n",
       "20                 0          0          0         0           0   \n",
       "21                 0          0          0         0           1   \n",
       "22                 1          0          0         0           0   \n",
       "23                 0          0          1         0           0   \n",
       "24                 0          0          0         0           0   \n",
       "\n",
       "    cat0_Sports & Outdoors  cat0_Women  \n",
       "0                        0           1  \n",
       "1                        0           1  \n",
       "2                        0           0  \n",
       "3                        0           0  \n",
       "4                        0           0  \n",
       "5                        0           0  \n",
       "6                        0           1  \n",
       "7                        0           1  \n",
       "8                        0           0  \n",
       "9                        0           0  \n",
       "10                       0           1  \n",
       "11                       0           0  \n",
       "12                       0           0  \n",
       "13                       1           0  \n",
       "14                       0           0  \n",
       "15                       0           0  \n",
       "16                       0           0  \n",
       "17                       0           0  \n",
       "18                       0           0  \n",
       "19                       0           1  \n",
       "20                       0           1  \n",
       "21                       0           0  \n",
       "22                       0           0  \n",
       "23                       0           0  \n",
       "24                       0           1  \n",
       "\n",
       "[25 rows x 3073 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14785, 7413]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-f2476ded8ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Std Dev:   '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14785, 7413]"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(XGBRegressor(), data.select_dtypes(include=[np.number]), y, cv=4, scoring='r2')\n",
    ".15\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.050000000000000003, max_features=None,\n",
      "        min_df=5, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      " ...=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
      "       subsample=1))])\n",
      "Mean score: 0.148614382105\n",
      "Std Dev:    0.00774860153297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = data['name']\n",
    "x.fillna('_BLANK_', inplace=True)\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', XGBRegressor())\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'tfidf__max_df': np.arange(.01,.11,.01),\n",
    "    'tfidf__min_df': np.arange(1,11,1),\n",
    "    'tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__norm': ['l2'],\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "print(model)\n",
    "cv = cross_val_score(model, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: -0.522018033764\n",
      "Std Dev:    0.00297008563967\n"
     ]
    }
   ],
   "source": [
    "brands = pd.get_dummies(data['brand'], prefix='brand')\n",
    "data = pd.concat([data, brands], axis=1)\n",
    "\n",
    "cv = cross_val_score(XGBRegressor(), data.select_dtypes(include=[np.number]), y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.161377200846\n",
      "Std Dev:    0.00702022371952\n"
     ]
    }
   ],
   "source": [
    "x = pd.get_dummies(cats)\n",
    "\n",
    "cv = cross_val_score(XGBRegressor(), x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.159613443153\n",
      "Std Dev:    0.00645306558285\n"
     ]
    }
   ],
   "source": [
    "cats = data['category_name'].str.split('/', expand=True, n=3)\n",
    "cats.columns = ['category_' + str(i) for i in cats.columns]\n",
    "data = pd.concat([data, cats], axis=1)\n",
    "\n",
    "x = pd.get_dummies(cats)\n",
    "\n",
    "cv = cross_val_score(XGBRegressor(), x, y, cv=3, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 0.140731284087\n",
      "Std Dev:    0.00187840333916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = data['item_description']\n",
    "x.fillna(' ', inplace=True)\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_df=.1, min_df=10)),\n",
    "    ('classify', XGBRegressor())\n",
    "])\n",
    "\n",
    "cv = cross_val_score(pl, x, y, cv=3, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14825, 1482535]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c2325ead7c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Vince\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14825, 1482535]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = data['item_description']\n",
    "x.fillna(' ', inplace=True)\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classify', LinearRegression())\n",
    "])\n",
    "\n",
    "params = [{\n",
    "    'tfidf__max_df': np.arange(.01,.36,.05),\n",
    "    'tfidf__min_df': np.arange(1,51,10),\n",
    "    'tfidf__ngram_range': [(1,1)],\n",
    "    'tfidf__norm': ['l2'],\n",
    "    'classify__normalize': [False, True],\n",
    "}]\n",
    "\n",
    "grid =\\\n",
    "GridSearchCV(pl, cv=3, n_jobs=-1, param_grid=params, scoring='r2')\\\n",
    ".fit(x, y)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "print(model)\n",
    "cv = cross_val_score(model, x, y, cv=4, scoring='r2')\n",
    "\n",
    "print('Mean score:', cv.mean())\n",
    "print('Std Dev:   ', cv.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
